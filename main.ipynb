{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import click\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorlayer as tl\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "from tensorlayer.layers import DenseLayer, EmbeddingInputlayer, Seq2Seq, retrieve_seq_length_op2\n",
    "from data.chat import pre\n",
    "\n",
    "sess_config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)\n",
    "\n",
    "\"\"\"\n",
    "Training model [optional args]\n",
    "\"\"\"\n",
    "@click.command()\n",
    "@click.option('-dc', '--data-corpus', default='chat', help='Data corpus to use for training and inference',)\n",
    "@click.option('-bs', '--batch-size', default=32, help='Batch size for training on minibatches',)\n",
    "@click.option('-n', '--num-epochs', default=20, help='Number of epochs for training',)\n",
    "@click.option('-lr', '--learning-rate', default=0.001, help='Learning rate to use when training model',)\n",
    "@click.option('-inf', '--inference-mode', is_flag=True, help='Flag for INFERENCE mode',)\n",
    "def train(data_corpus, batch_size, num_epochs, learning_rate, inference_mode):\n",
    "\n",
    "    metadata, trainX, trainY, testX, testY, validX, validY = initial_setup(data_corpus)\n",
    "\n",
    "    # Parameters\n",
    "    src_len = len(trainX)\n",
    "    tgt_len = len(trainY)\n",
    "\n",
    "    assert src_len == tgt_len\n",
    "\n",
    "    n_step = src_len // batch_size\n",
    "    src_vocab_size = len(metadata['idx2w']) # 8002 (0~8001)\n",
    "    emb_dim = 1024\n",
    "\n",
    "    word2idx = metadata['w2idx']   # dict  word 2 index\n",
    "    idx2word = metadata['idx2w']   # list index 2 word\n",
    "\n",
    "    unk_id = word2idx['unk']   # 1\n",
    "    pad_id = word2idx['_']     # 0\n",
    "\n",
    "    start_id = src_vocab_size  # 8002\n",
    "    end_id = src_vocab_size + 1  # 8003\n",
    "\n",
    "    word2idx.update({'start_id': start_id})\n",
    "    word2idx.update({'end_id': end_id})\n",
    "    idx2word = idx2word + ['start_id', 'end_id']\n",
    "\n",
    "    src_vocab_size = tgt_vocab_size = src_vocab_size + 2\n",
    "\n",
    "    \"\"\" A data for Seq2Seq should look like this:\n",
    "    input_seqs : ['how', 'are', 'you', '<PAD_ID'>]\n",
    "    decode_seqs : ['<START_ID>', 'I', 'am', 'fine', '<PAD_ID'>]\n",
    "    target_seqs : ['I', 'am', 'fine', '<END_ID>', '<PAD_ID'>]\n",
    "    target_mask : [1, 1, 1, 1, 0]\n",
    "    \"\"\"\n",
    "    # Preprocessing\n",
    "    target_seqs = tl.prepro.sequences_add_end_id([trainY[10]], end_id=end_id)[0]\n",
    "    decode_seqs = tl.prepro.sequences_add_start_id([trainY[10]], start_id=start_id, remove_last=False)[0]\n",
    "    target_mask = tl.prepro.sequences_get_mask([target_seqs])[0]\n",
    "    if not inference_mode:\n",
    "        print(\"encode_seqs\", [idx2word[id] for id in trainX[10]])\n",
    "        print(\"target_seqs\", [idx2word[id] for id in target_seqs])\n",
    "        print(\"decode_seqs\", [idx2word[id] for id in decode_seqs])\n",
    "        print(\"target_mask\", target_mask)\n",
    "        print(len(target_seqs), len(decode_seqs), len(target_mask))\n",
    "\n",
    "    # Init Session\n",
    "    tf.reset_default_graph()\n",
    "    sess = tf.Session(config=sess_config)\n",
    "\n",
    "    # Training Data Placeholders\n",
    "    encode_seqs = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"encode_seqs\")\n",
    "    decode_seqs = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"decode_seqs\")\n",
    "    target_seqs = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"target_seqs\")\n",
    "    target_mask = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"target_mask\") \n",
    "\n",
    "    net_out, _ = create_model(encode_seqs, decode_seqs, src_vocab_size, emb_dim, is_train=True, reuse=False)\n",
    "    net_out.print_params(False)\n",
    "\n",
    "    # Inference Data Placeholders\n",
    "    encode_seqs2 = tf.placeholder(dtype=tf.int64, shape=[1, None], name=\"encode_seqs\")\n",
    "    decode_seqs2 = tf.placeholder(dtype=tf.int64, shape=[1, None], name=\"decode_seqs\")\n",
    "\n",
    "    net, net_rnn = create_model(encode_seqs2, decode_seqs2, src_vocab_size, emb_dim, is_train=False, reuse=True)\n",
    "    y = tf.nn.softmax(net.outputs)\n",
    "\n",
    "    # Loss Function\n",
    "    loss = tl.cost.cross_entropy_seq_with_mask(logits=net_out.outputs, target_seqs=target_seqs, \n",
    "                                                input_mask=target_mask, return_details=False, name='cost')\n",
    "\n",
    "    # Optimizer\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "    # Init Vars\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Load Model\n",
    "    tl.files.load_and_assign_npz(sess=sess, name='model.npz', network=net)\n",
    "\n",
    "    \"\"\"\n",
    "    Inference using pre-trained model\n",
    "    \"\"\"\n",
    "    def inference(seed):\n",
    "        seed_id = [word2idx.get(w, unk_id) for w in seed.split(\" \")]\n",
    "        \n",
    "        # Encode and get state\n",
    "        state = sess.run(net_rnn.final_state_encode,\n",
    "                        {encode_seqs2: [seed_id]})\n",
    "        # Decode, feed start_id and get first word [https://github.com/zsdonghao/tensorlayer/blob/master/example/tutorial_ptb_lstm_state_is_tuple.py]\n",
    "        o, state = sess.run([y, net_rnn.final_state_decode],\n",
    "                        {net_rnn.initial_state_decode: state,\n",
    "                        decode_seqs2: [[start_id]]})\n",
    "        w_id = tl.nlp.sample_top(o[0], top_k=3)\n",
    "        w = idx2word[w_id]\n",
    "        # Decode and feed state iteratively\n",
    "        sentence = [w]\n",
    "        for _ in range(30): # max sentence length\n",
    "            o, state = sess.run([y, net_rnn.final_state_decode],\n",
    "                            {net_rnn.initial_state_decode: state,\n",
    "                            decode_seqs2: [[w_id]]})\n",
    "            w_id = tl.nlp.sample_top(o[0], top_k=2)\n",
    "            w = idx2word[w_id]\n",
    "            if w_id == end_id:\n",
    "                break\n",
    "            sentence = sentence + [w]\n",
    "        return sentence\n",
    "\n",
    "    if inference_mode:\n",
    "        print('Inference Mode')\n",
    "        print('--------------')\n",
    "        while True:\n",
    "            input_seq = input('Enter Query: ')\n",
    "            sentence = inference(input_seq)\n",
    "            print(\" >\", ' '.join(sentence))\n",
    "    else:\n",
    "        seeds = [\"happy birthday have a nice day\",\n",
    "                 \"donald trump won last nights presidential debate according to snap online polls\"]\n",
    "        for epoch in range(num_epochs):\n",
    "            trainX, trainY = shuffle(trainX, trainY, random_state=0)\n",
    "            total_loss, n_iter = 0, 0\n",
    "            for X, Y in tqdm(tl.iterate.minibatches(inputs=trainX, targets=trainY, batch_size=batch_size, shuffle=False), \n",
    "                            total=n_step, desc='Epoch[{}/{}]'.format(epoch + 1, num_epochs), leave=False):\n",
    "\n",
    "                X = tl.prepro.pad_sequences(X)\n",
    "                _target_seqs = tl.prepro.sequences_add_end_id(Y, end_id=end_id)\n",
    "                _target_seqs = tl.prepro.pad_sequences(_target_seqs)\n",
    "                _decode_seqs = tl.prepro.sequences_add_start_id(Y, start_id=start_id, remove_last=False)\n",
    "                _decode_seqs = tl.prepro.pad_sequences(_decode_seqs)\n",
    "                _target_mask = tl.prepro.sequences_get_mask(_target_seqs)\n",
    "                ## Uncomment to view the data here\n",
    "                # for i in range(len(X)):\n",
    "                #     print(i, [idx2word[id] for id in X[i]])\n",
    "                #     print(i, [idx2word[id] for id in Y[i]])\n",
    "                #     print(i, [idx2word[id] for id in _target_seqs[i]])\n",
    "                #     print(i, [idx2word[id] for id in _decode_seqs[i]])\n",
    "                #     print(i, _target_mask[i])\n",
    "                #     print(len(_target_seqs[i]), len(_decode_seqs[i]), len(_target_mask[i]))\n",
    "                _, loss_iter = sess.run([train_op, loss], {encode_seqs: X, decode_seqs: _decode_seqs,\n",
    "                                target_seqs: _target_seqs, target_mask: _target_mask})\n",
    "                total_loss += loss_iter\n",
    "                n_iter += 1\n",
    "\n",
    "            # printing average loss after every epoch\n",
    "            print('Epoch [{}/{}]: loss {:.4f}'.format(epoch + 1, num_epochs, total_loss / n_iter))\n",
    "            \n",
    "            # inference after every epoch\n",
    "            for seed in seeds:\n",
    "                print(\"Query >\", seed)\n",
    "                for _ in range(5):\n",
    "                    sentence = inference(seed)\n",
    "                    print(\" >\", ' '.join(sentence))\n",
    "            \n",
    "            # saving the model\n",
    "            tl.files.save_npz(net.all_params, name='model.npz', sess=sess)\n",
    "    \n",
    "    # session cleanup\n",
    "    sess.close()\n",
    "\n",
    "\"\"\"\n",
    "Creates the LSTM Model\n",
    "\"\"\"\n",
    "def create_model(encode_seqs, decode_seqs, src_vocab_size, emb_dim, is_train=True, reuse=False):\n",
    "    with tf.variable_scope(\"model\", reuse=reuse):\n",
    "        # for chatbot, you can use the same embedding layer,\n",
    "        # for translation, you may want to use 2 seperated embedding layers\n",
    "        with tf.variable_scope(\"embedding\") as vs:\n",
    "            net_encode = EmbeddingInputlayer(\n",
    "                inputs = encode_seqs,\n",
    "                vocabulary_size = src_vocab_size,\n",
    "                embedding_size = emb_dim,\n",
    "                name = 'seq_embedding')\n",
    "            vs.reuse_variables()\n",
    "            net_decode = EmbeddingInputlayer(\n",
    "                inputs = decode_seqs,\n",
    "                vocabulary_size = src_vocab_size,\n",
    "                embedding_size = emb_dim,\n",
    "                name = 'seq_embedding')\n",
    "            \n",
    "        net_rnn = Seq2Seq(net_encode, net_decode,\n",
    "                cell_fn = tf.nn.rnn_cell.LSTMCell,\n",
    "                n_hidden = emb_dim,\n",
    "                initializer = tf.random_uniform_initializer(-0.1, 0.1),\n",
    "                encode_sequence_length = retrieve_seq_length_op2(encode_seqs),\n",
    "                decode_sequence_length = retrieve_seq_length_op2(decode_seqs),\n",
    "                initial_state_encode = None,\n",
    "                dropout = (0.5 if is_train else None),\n",
    "                n_layer = 3,\n",
    "                return_seq_2d = True,\n",
    "                name = 'seq2seq')\n",
    "\n",
    "        net_out = DenseLayer(net_rnn, n_units=src_vocab_size, act=tf.identity, name='output')\n",
    "    return net_out, net_rnn\n",
    "\n",
    "\"\"\"\n",
    "Initial Setup\n",
    "\"\"\"\n",
    "def initial_setup(data_corpus):\n",
    "    metadata, idx_q, idx_a = pre.load_data(PATH='data/{}/'.format(data_corpus))\n",
    "    (trainX, trainY), (testX, testY), (validX, validY) = pre.split_dataset(idx_q, idx_a)\n",
    "    trainX = tl.prepro.remove_pad_sequences(trainX.tolist())\n",
    "    trainY = tl.prepro.remove_pad_sequences(trainY.tolist())\n",
    "    testX = tl.prepro.remove_pad_sequences(testX.tolist())\n",
    "    testY = tl.prepro.remove_pad_sequences(testY.tolist())\n",
    "    validX = tl.prepro.remove_pad_sequences(validX.tolist())\n",
    "    validY = tl.prepro.remove_pad_sequences(validY.tolist())\n",
    "    return metadata, trainX, trainY, testX, testY, validX, validY\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        train()\n",
    "    except KeyboardInterrupt:\n",
    "        print('Aborted!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnsupportedOperation",
     "evalue": "not writable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchOption\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/my_root/lib/python3.6/site-packages/click/parser.py\u001b[0m in \u001b[0;36m_process_opts\u001b[0;34m(self, arg, state)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_match_long_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm_long_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplicit_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mNoSuchOption\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/my_root/lib/python3.6/site-packages/click/parser.py\u001b[0m in \u001b[0;36m_match_long_opt\u001b[0;34m(self, opt, explicit_value, state)\u001b[0m\n\u001b[1;32m    323\u001b[0m                              if word.startswith(opt)]\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mNoSuchOption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibilities\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpossibilities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNoSuchOption\u001b[0m: no such option: -f",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNoSuchOption\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/my_root/lib/python3.6/site-packages/click/core.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(self, args, prog_name, complete_var, standalone_mode, **extra)\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprog_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextra\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m                     \u001b[0mrv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/my_root/lib/python3.6/site-packages/click/core.py\u001b[0m in \u001b[0;36mmake_context\u001b[0;34m(self, info_name, args, parent, **extra)\u001b[0m\n\u001b[1;32m    620\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleanup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/my_root/lib/python3.6/site-packages/click/core.py\u001b[0m in \u001b[0;36mparse_args\u001b[0;34m(self, ctx, args)\u001b[0m\n\u001b[1;32m    875\u001b[0m         \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 876\u001b[0;31m         \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_order\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/my_root/lib/python3.6/site-packages/click/parser.py\u001b[0m in \u001b[0;36mparse_args\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_args_for_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_args_for_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/my_root/lib/python3.6/site-packages/click/parser.py\u001b[0m in \u001b[0;36m_process_args_for_options\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opt_prefixes\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marglen\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_opts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_interspersed_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/my_root/lib/python3.6/site-packages/click/parser.py\u001b[0m in \u001b[0;36m_process_opts\u001b[0;34m(self, arg, state)\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opt_prefixes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_match_short_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_unknown_options\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/my_root/lib/python3.6/site-packages/click/parser.py\u001b[0m in \u001b[0;36m_match_short_opt\u001b[0;34m(self, arg, state)\u001b[0m\n\u001b[1;32m    366\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mNoSuchOption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0moption\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtakes_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNoSuchOption\u001b[0m: no such option: -f",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnsupportedOperation\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-58ca95c5b364>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-b4b36fcec3be>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Aborted!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/my_root/lib/python3.6/site-packages/click/core.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;34m\"\"\"Alias for :meth:`main`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/my_root/lib/python3.6/site-packages/click/core.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(self, args, prog_name, complete_var, standalone_mode, **extra)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstandalone_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m                 \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/my_root/lib/python3.6/site-packages/click/exceptions.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, file)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mecho\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mecho\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Error: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/my_root/lib/python3.6/site-packages/click/utils.py\u001b[0m in \u001b[0;36mecho\u001b[0;34m(message, file, nl, err, color)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m     \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnsupportedOperation\u001b[0m: not writable"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
